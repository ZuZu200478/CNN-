# å®‰è£å¿…è¦å¥—ä»¶ï¼ˆåªéœ€å®‰è£ä¸€æ¬¡ï¼‰
install.packages("keras")
install.packages("magick")
install.packages("caret")

# è¼‰å…¥å¥—ä»¶
library(keras)
library(magick)
library(caret)

# å®‰è£ Keras å’Œ TensorFlowï¼ˆåªéœ€åŸ·è¡Œä¸€æ¬¡ï¼‰
install_keras()

# åœ–ç‰‡å¤§å°
img_size <- c(150, 150)

# è¨­å®šè³‡æ–™å¤¾è·¯å¾‘
train_dir <- "C:/Users/Win/Desktop/data analyze/final exam/train"
valid_dir <- "C:/Users/Win/Desktop/data analyze/final exam/test"

# å»ºç«‹è³‡æ–™ç”¢ç”Ÿå™¨
train_gen <- image_data_generator(rescale = 1/255)
valid_gen <- image_data_generator(rescale = 1/255)

# è¼‰å…¥è¨“ç·´èˆ‡é©—è­‰è³‡æ–™
train_data <- flow_images_from_directory(
  directory = train_dir,
  generator = train_gen,
  target_size = img_size,
  batch_size = 32,
  class_mode = "binary"
)

valid_data <- flow_images_from_directory(
  directory = valid_dir,
  generator = valid_gen,
  target_size = img_size,
  batch_size = 32,
  class_mode = "binary"
)

# å»ºç«‹ CNN æ¨¡å‹
model <- keras_model_sequential() %>%
  layer_conv_2d(filters = 32, kernel_size = c(3,3), activation = "relu", input_shape = c(150,150,3)) %>%
  layer_max_pooling_2d(pool_size = c(2,2)) %>%
  layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2,2)) %>%
  layer_conv_2d(filters = 128, kernel_size = c(3,3), activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2,2)) %>%
  layer_flatten() %>%
  layer_dense(units = 512, activation = "relu") %>%
  layer_dropout(0.5) %>%
  layer_dense(units = 1, activation = "sigmoid")

# ç·¨è­¯æ¨¡å‹
model %>% compile(
  loss = "binary_crossentropy",
  optimizer = optimizer_adam(),
  metrics = "accuracy"
)

# è¨“ç·´æ¨¡å‹
history <- model %>% fit(
  train_data,
  steps_per_epoch = 100,
  epochs = 10,
  validation_data = valid_data,
)

# ===============================
# ğŸ§ª æ¸¬è©¦æ¨¡å‹ä¸¦ç”¢ç”Ÿæ··æ·†çŸ©é™£
# ===============================

# æ¸¬è©¦è³‡æ–™å¤¾å…§åœ–ç‰‡è·¯å¾‘
files <- list.files(valid_dir, full.names = TRUE, pattern = "\\.jpg$", recursive = TRUE)

# ä½ å¯ä»¥æ”¹æˆè¦æ¸¬å¹¾å¼µ
n <- length(files)

# å»ºç«‹çœŸå¯¦èˆ‡é æ¸¬æ¨™ç±¤çš„å®¹å™¨
y_true <- c()
y_pred <- c()

for (file in files[1:n]) {
  # æ ¹æ“šæª”ååˆ¤æ–·çœŸå¯¦æ¨™ç±¤
  if (grepl("cat", basename(file), ignore.case = TRUE)) {
    y_true <- c(y_true, 0)
  } else if (grepl("dog", basename(file), ignore.case = TRUE)) {
    y_true <- c(y_true, 1)
  } else {
    next  # è·³ééè²“ç‹—åœ–
  }
  
  # åœ–ç‰‡å‰è™•ç† + é æ¸¬
  img <- image_load(file, target_size = img_size)
  img_array <- image_to_array(img)
  img_array <- array_reshape(img_array, c(1, 150, 150, 3))
  img_array <- img_array / 255
  
  pred <- model %>% predict(img_array)
  y_pred <- c(y_pred, ifelse(pred < 0.5, 0, 1))
}

# è½‰æˆåˆ†é¡æ¨™ç±¤ï¼ˆæ–‡å­—ï¼‰
y_true <- factor(y_true, levels = c(0,1), labels = c("cat", "dog"))
y_pred <- factor(y_pred, levels = c(0,1), labels = c("cat", "dog"))

# æ··æ·†çŸ©é™£
conf_mat <- confusionMatrix(y_pred, y_true)
print(conf_mat)
